% Bibliography section would typically go at the end of the document
% Here are the references in bibtex format for inclusion in your bibliography:

@article{arxiv:2402.04437,
    author = {Zhao, Donghan and Tan, Jinhyuk and Yu, Yinan and Shu, Chang and Chen, Wenhu},
    title = {Structured Entity Extraction Using Large Language Models},
    journal = {arXiv preprint arXiv:2402.04437},
    year = {2024},
    url = {https://arxiv.org/html/2402.04437v3}
}

@article{arxiv:2403.02130,
    author = {Brinkmann, Alexander and Bizer, Christian and Vaisman, Mahsa},
    title = {Using LLMs for the Extraction and Normalization of Product Attribute Values},
    journal = {arXiv preprint arXiv:2403.02130},
    year = {2024},
    url = {https://arxiv.org/abs/2403.02130}
}

@article{arxiv:2310.14735,
    author = {Chen, Banghao and Chen, Zhen and Huang, Xuantang and Wei, Jie},
    title = {Unleashing the potential of prompt engineering for large language models},
    journal = {arXiv preprint arXiv:2310.14735},
    year = {2023},
    url = {https://arxiv.org/abs/2310.14735}
}

@article{arxiv:2407.15788,
    author = {Dolphin, Rian and Warwick-Ching, Theo and Jiang, Yijie and Zhang, Yitong and Leemaqz, Kay Lie and Zhu, William Wei},
    title = {Extracting Structured Insights from Financial News: An Augmented LLM Driven Approach},
    journal = {arXiv preprint arXiv:2407.15788},
    year = {2024},
    url = {https://arxiv.org/abs/2407.15788}
}

@article{nature:s41467-024-45563-x,
    author = {Gupta, Amalie and Delaney-Busch, Nathaniel and Symes, Alexander K. and Das, Ankur and Sahasrabudhe, Mihir and McElhinney, Kevin and Dey, Biswanath and Agarwal, Prateek and Gomez-Bombarelli, Rafael},
    title = {Structured information extraction from scientific text with large language models},
    journal = {Nature Communications},
    volume = {15},
    number = {1},
    pages = {1922},
    year = {2024},
    doi = {10.1038/s41467-024-45563-x},
    url = {https://www.nature.com/articles/s41467-024-45563-x}
}

@article{arxiv:2402.07927,
    author = {Li, Yanjun and Li, Shuzhi and Behera, Biswesh and Yadav, Gurvinder and Katalinic, Maja},
    title = {A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications},
    journal = {arXiv preprint arXiv:2402.07927},
    year = {2024},
    url = {https://arxiv.org/abs/2402.07927}
}

@article{wiley:9989471,
    author = {Li, Chaohui and Qi, Jianhua and Li, Peiyan and Liu, Qian},
    title = {A Parallel Attribute Reduction Method Based on Classification},
    journal = {Complexity},
    volume = {2021},
    pages = {9989471},
    year = {2021},
    publisher = {Wiley},
    doi = {10.1155/2021/9989471},
    url = {https://onlinelibrary.wiley.com/doi/10.1155/2021/9989471}
}

@article{arxiv:1706.06697,
    author = {Gross, Florian},
    title = {Index Search Algorithms for Databases and Modern CPUs},
    journal = {arXiv preprint arXiv:1706.06697},
    year = {2017},
    url = {https://arxiv.org/abs/1706.06697}
}



@article{arxiv:2106.14624,
    author = {Schmidt, Tobias and Wolff, Michaela and Holzinger, Kevin and Kost, Jakob and Ficek, Marian and Haderlein, Thomas and Laasch, Cornelius and Röding, Daniel and Brandes, Marco and Palenicek, Rudolf and others},
    title = {Key Information Extraction From Documents: Evaluation And Generator},
    journal = {arXiv preprint arXiv:2106.14624},
    year = {2021},
    url = {https://arxiv.org/abs/2106.14624}
}

@article{arxiv:2410.21169,
    author = {Zhou, Jinyu and Shi, Yi and Fan, Wei and Li, Dongji and Zeng, Yue and Liao, Junpeng and Wang, Boyuan and Wu, Pengyu and Jiao, Gang and Li, Guangpin and Xi, Hang and others},
    title = {Document Parsing Unveiled: Techniques, Challenges, and Prospects for Structured Information Extraction},
    journal = {arXiv preprint arXiv:2410.21169},
    year = {2024},
    url = {https://arxiv.org/html/2410.21169v2}
}

@article{arxiv:2402.07927,
    author = {Li, Yanjun and Li, Shuzhi and Behera, Biswesh and Yadav, Gurvinder and Katalinic, Maja},
    title = {A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications},
    journal = {arXiv preprint arXiv:2402.07927},
    year = {2024},
    url = {https://arxiv.org/abs/2402.07927}
}

@article{arxiv:2310.14735,
    author = {Chen, Banghao and Chen, Zhen and Huang, Xuantang and Wei, Jie},
    title = {Unleashing the potential of prompt engineering for large language models},
    journal = {arXiv preprint arXiv:2310.14735},
    year = {2023},
    url = {https://arxiv.org/abs/2310.14735}
}

@article{wiley:9989471,
    author = {Li, Chaohui and Qi, Jianhua and Li, Peiyan and Liu, Qian},
    title = {A Parallel Attribute Reduction Method Based on Classification},
    journal = {Complexity},
    volume = {2021},
    pages = {9989471},
    year = {2021},
    publisher = {Wiley},
    doi = {10.1155/2021/9989471},
    url = {https://onlinelibrary.wiley.com/doi/10.1155/2021/9989471}
}

@article{arxiv:1706.06697,
    author = {Gross, Florian},
    title = {Index Search Algorithms for Databases and Modern CPUs},
    journal = {arXiv preprint arXiv:1706.06697},
    year = {2017},
    url = {https://arxiv.org/abs/1706.06697}
}

@inbook{marinai2008,
  author = {Marinai, Simone},
  title = {Introduction to Document Analysis and Recognition},
  booktitle = {Machine Learning in Document Analysis and Recognition},
  editor = {Marinai, Simone and Fujisawa, Hiromichi},
  year = {2008},
  pages = {1--20},
  publisher = {Springer}
}

@article{li2021,
  title = {A Survey on Deep Learning for Named Entity Recognition},
  author = {Li, Jing and Sun, Aixin and Han, Jianglei and Li, Chenliang},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {34},
  number = {1},
  pages = {50--70},
  year = {2021}
}

@inproceedings{wei2022,
  title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {35},
  year = {2022}
}

@article{huang2023,
  title = {Structured Prediction with Language Models},
  author = {Huang, Shuyan and Zellers, Rowan and Rashkin, Hannah and Choi, Yejin},
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {11},
  pages = {452--468},
  year = {2023}
}

@article{guyon2003,
  title = {An Introduction to Variable and Feature Selection},
  author = {Guyon, Isabelle and Elisseeff, André},
  journal = {Journal of Machine Learning Research},
  volume = {3},
  pages = {1157--1182},
  year = {2003}
}

@article{fagin2003,
  title = {Extendible Hashing—A Fast Access Method for Dynamic Files},
  author = {Fagin, Ronald and Nievergelt, Jurg and Pippenger, Nicholas and Strong, H. Raymond},
  journal = {ACM Transactions on Database Systems},
  volume = {4},
  number = {3},
  pages = {315--344},
  year = {2003}
}


@article{Vaswani2017,
  title = {Attention is all you need},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  journal = {Advances in Neural Information Processing Systems},
  volume = {30},
  year = {2017}
}
@article{Lakoff2008,
  title = {The neural theory of metaphor},
  author = {Lakoff, George},
  journal = {The Cambridge Handbook of Metaphor and Thought},
  volume = {17},
  year = {2008}
}
@article{Rumelhart1980,
  title = {Schemata: The building blocks of cognition},
  author = {Rumelhart, David E.},
  journal = {Theoretical Issues in Reading Comprehension},
  pages = {33--58},
  year = {1980}
}
@article{Shannon1948,
  title = {A mathematical theory of communication},
  author = {Shannon, Claude E.},
  journal = {The Bell System Technical Journal},
  volume = {27},
  number = {3},
  pages = {379--423},
  year = {1948}
}
%
@article{Wang2024,
  title = {Are LLMs good at structured outputs? A benchmark for evaluating structured output capabilities in LLMs},
  author = {Wang, Shi and Li, Chenglei and Zhao, Wayne Xin and Du, Bo and Wen, Ji-Rong},
  journal = {Information Processing \& Management},
  volume = {61},
  number = {6},
  pages = {103687},
  year = {2024},
  doi = {10.1016/j.ipm.2024.103687}
}
@article{Lu2022,
  title = {Neurologic decoding: Constrained natural language generation with LLMs},
  author = {Lu, Ximing and West, Peter and Zoph, Barret and Iyer, Rohan and Wang, Le and Dubey, Abhijit and Xie, Nan},
  journal = {arXiv preprint arXiv:2212.10559},
  year = {2022}
}
@misc{Castillo2024,
  title = {The good, the bad, and the ugly of Gemini's structured outputs},
  author = {Castillo, Dylan},
  year = {2024},
  howpublished = {\url{https://dylancastillo.co/posts/gemini-structured-outputs.html}}
}
@misc{GoogleDeepMind2025,
  title = {Gemini 2.5 Flash},
  author = {{Google DeepMind}},
  year = {2025},
  howpublished = {\url{https://deepmind.google/technologies/gemini/flash/}}
}
@misc{GoogleBlog2025,
  title = {Gemini 2.5: Our newest Gemini model with thinking},
  author = {{Google Blog}},
  year = {2025},
  month = {March},
  howpublished = {\url{https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/}}
}

@misc{Schmid2025,
  title = {From PDFs to Insights: Structured Outputs from PDFs with Gemini 2.0},
  author = {Schmid, Philipp},
  year = {2025},
  month = {February},
  howpublished = {\url{https://www.philschmid.de/gemini-pdf-to-data}}
}

@misc{Instructor2024,
  title = {Structured Outputs for Gemini now supported},
  author = {{Instructor}},
  year = {2024},
  month = {September},
  howpublished = {\url{https://python.useinstructor.com/blog/2024/09/03/structured-outputs-for-gemini-now-supported/}}
}
%
@misc{DotTXT2024,
  title = {Structured Generation Improves LLM performance: GSM8K Benchmark},
  author = {{DotTXT}},
  year = {2024},
  howpublished = {\url{https://blog.dottxt.co/performance-gsm8k.html}}
}
@misc{DataChain2024,
  title = {Enforcing JSON Outputs in Commercial LLMs},
  author = {{DataChain}},
  year = {2024},
  month = {September},
  howpublished = {\url{https://datachain.ai/blog/enforcing-json-outputs-in-commercial-llms}}
}
@misc{OpenAI2024,
  title = {Function calling and JSON mode},
  author = {{OpenAI}},
  year = {2024},
  howpublished = {\url{https://platform.openai.com/docs/guides/function-calling}}
}
@misc{Anthropic2024,
  title = {Tool use},
  author = {{Anthropic}},
  year = {2024},
  howpublished = {\url{https://docs.anthropic.com/claude/docs/tool-use}}
}
@misc{Mistral2024,
  title = {Mistral Large API documentation},
  author = {{Mistral AI}},
   year = {2024},
   howpublished = {\url{https://docs.mistral.ai/api/}}
}